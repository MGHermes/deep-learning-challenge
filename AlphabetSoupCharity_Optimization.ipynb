{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB-igPWI5l1-"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kerastuner\n",
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "PplHnh3PT74b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3448c801-4dee-4c06-f46a-58aa36d8fde1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "bevakBLv5l1_",
        "outputId": "d27babb2-1605-4c91-fde3-5703efb96596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a1cb6ae-9f70-4ac0-a08f-578c6410ebd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a1cb6ae-9f70-4ac0-a08f-578c6410ebd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a1cb6ae-9f70-4ac0-a08f-578c6410ebd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a1cb6ae-9f70-4ac0-a08f-578c6410ebd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd \n",
        "application_df = pd.read_csv(\"charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "U7kfSdYs5l2A",
        "outputId": "e718aeea-d767-4150-bf4c-8af665ff44b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0              T10       Independent          C1000    ProductDev   \n",
              "1               T3       Independent          C2000  Preservation   \n",
              "2               T5  CompanySponsored          C3000    ProductDev   \n",
              "3               T3  CompanySponsored          C2000  Preservation   \n",
              "4               T3       Independent          C1000     Heathcare   \n",
              "\n",
              "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
              "0   Association       1              0                      N     5000   \n",
              "1  Co-operative       1         1-9999                      N   108590   \n",
              "2   Association       1              0                      N     5000   \n",
              "3         Trust       1    10000-24999                      N     6692   \n",
              "4         Trust       1  100000-499999                      N   142590   \n",
              "\n",
              "   IS_SUCCESSFUL  \n",
              "0              1  \n",
              "1              1  \n",
              "2              0  \n",
              "3              1  \n",
              "4              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52d9c186-6bb7-4b66-9387-7da4c0a5e1d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d9c186-6bb7-4b66-9387-7da4c0a5e1d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52d9c186-6bb7-4b66-9387-7da4c0a5e1d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52d9c186-6bb7-4b66-9387-7da4c0a5e1d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(['EIN', 'NAME'], axis=1)\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the noisy variables\n",
        "application_df = application_df.drop(['STATUS', 'SPECIAL_CONSIDERATIONS'], axis=1)\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lQGDQpT5i2nU",
        "outputId": "680d168d-40c2-4a4a-eea5-19fe59b981ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0              T10       Independent          C1000    ProductDev   \n",
              "1               T3       Independent          C2000  Preservation   \n",
              "2               T5  CompanySponsored          C3000    ProductDev   \n",
              "3               T3  CompanySponsored          C2000  Preservation   \n",
              "4               T3       Independent          C1000     Heathcare   \n",
              "\n",
              "   ORGANIZATION     INCOME_AMT  ASK_AMT  IS_SUCCESSFUL  \n",
              "0   Association              0     5000              1  \n",
              "1  Co-operative         1-9999   108590              1  \n",
              "2   Association              0     5000              0  \n",
              "3         Trust    10000-24999     6692              1  \n",
              "4         Trust  100000-499999   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-910e2522-051a-4d3c-8a36-185ee664f83b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>0</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>0</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-910e2522-051a-4d3c-8a36-185ee664f83b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-910e2522-051a-4d3c-8a36-185ee664f83b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-910e2522-051a-4d3c-8a36-185ee664f83b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9y0QOmB7Uuk",
        "outputId": "83bceeab-6a36-4ddb-f87b-7bab15cbdcf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE      17\n",
              "AFFILIATION            6\n",
              "CLASSIFICATION        71\n",
              "USE_CASE               5\n",
              "ORGANIZATION           4\n",
              "INCOME_AMT             9\n",
              "ASK_AMT             8747\n",
              "IS_SUCCESSFUL          2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylzSXh6A9apO",
        "outputId": "db801851-58a2-41d7-8221-946e499dc23f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = application_df['APPLICATION_TYPE'].value_counts().loc[lambda x : x < 500].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynm5zLwB93Y0",
        "outputId": "2545cb67-73ac-4581-b0bb-3e6dc1a4b360"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf6A8TcPBdj6",
        "outputId": "50b47ce6-e555-4642-f23b-666e9c88b624"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "application_df['CLASSIFICATION'].value_counts().loc[lambda x : x > 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNoJsQsVBqB1",
        "outputId": "c11ad020-aa6a-4b31-9db9-269806bf8d1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = application_df['CLASSIFICATION'].value_counts().loc[lambda x : x < 1800].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2EcbM-IEWpD",
        "outputId": "ae2b6370-7570-4460-8151-123e7199da4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "0DXJRUqE5l2B",
        "outputId": "a13cc697-18fe-4131-ae17-c2803c08d01b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
              "0     5000              1                       0                     1   \n",
              "1   108590              1                       0                     0   \n",
              "2     5000              0                       0                     0   \n",
              "3     6692              1                       0                     0   \n",
              "4   142590              1                       0                     0   \n",
              "\n",
              "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
              "0                     0                    0                    0   \n",
              "1                     0                    1                    0   \n",
              "2                     0                    0                    0   \n",
              "3                     0                    1                    0   \n",
              "4                     0                    1                    0   \n",
              "\n",
              "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
              "0                    0                    0                    0  ...   \n",
              "1                    0                    0                    0  ...   \n",
              "2                    1                    0                    0  ...   \n",
              "3                    0                    0                    0  ...   \n",
              "4                    0                    0                    0  ...   \n",
              "\n",
              "   ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
              "0                   0             1                  0   \n",
              "1                   0             0                  1   \n",
              "2                   0             1                  0   \n",
              "3                   1             0                  0   \n",
              "4                   1             0                  0   \n",
              "\n",
              "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                       0                         0                   0   \n",
              "1                       0                         0                   0   \n",
              "2                       0                         0                   0   \n",
              "3                       1                         0                   0   \n",
              "4                       0                         1                   0   \n",
              "\n",
              "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0                 0                       0                0   \n",
              "1                 0                       0                0   \n",
              "2                 0                       0                0   \n",
              "3                 0                       0                0   \n",
              "4                 0                       0                0   \n",
              "\n",
              "   INCOME_AMT_5M-10M  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  0  \n",
              "4                  0  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e20e796-0a42-4be7-807f-f5339aa8e74f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e20e796-0a42-4be7-807f-f5339aa8e74f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e20e796-0a42-4be7-807f-f5339aa8e74f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e20e796-0a42-4be7-807f-f5339aa8e74f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_dum_df = pd.get_dummies(application_df)\n",
        "application_dum_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NODZLsQR5l2B"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = application_dum_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
        "y = application_dum_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e0y56nB-5l2B"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZri27J15l2B"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32 and 512\n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "  model.add(keras.layers.Dense(units = hp_units, activation = 'sigmoid'))\n",
        "  model.add(keras.layers.Dense(units = hp_units, activation = 'sigmoid'))\n",
        "  model.add(keras.layers.Dense(units = hp_units, activation = 'sigmoid'))\n",
        "  model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "o6UuavFBUduT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy',\n",
        "                     max_epochs = 10,\n",
        "                     factor = 3,\n",
        "                     directory = 'deep-learning-challenge',\n",
        "                     project_name = 'AlphabetSoupCharity_Optimization')"
      ],
      "metadata": {
        "id": "Cnon_qzvWHnZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 5)"
      ],
      "metadata": {
        "id": "35EL6fXZXdxv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train_scaled, y_train, epochs = 20, validation_split = 0.2, callbacks = [stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGgvEDJEXw5r",
        "outputId": "d32218c0-b9e5-44e9-b084-6a68d0c16d83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 25s]\n",
            "val_accuracy: 0.7331389784812927\n",
            "\n",
            "Best val_accuracy So Far: 0.7379980683326721\n",
            "Total elapsed time: 00h 09m 40s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 416 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_scaled, y_train, epochs = 200, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCOxTBZ6eNXe",
        "outputId": "22809bb6-af0d-4577-b12c-e2bffdf2c1d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.6150 - accuracy: 0.6855 - val_loss: 0.5724 - val_accuracy: 0.7259\n",
            "Epoch 2/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5785 - accuracy: 0.7182 - val_loss: 0.5779 - val_accuracy: 0.7219\n",
            "Epoch 3/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5691 - accuracy: 0.7217 - val_loss: 0.5563 - val_accuracy: 0.7353\n",
            "Epoch 4/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5630 - accuracy: 0.7256 - val_loss: 0.5670 - val_accuracy: 0.7250\n",
            "Epoch 5/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5601 - accuracy: 0.7281 - val_loss: 0.5519 - val_accuracy: 0.7357\n",
            "Epoch 6/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5586 - accuracy: 0.7279 - val_loss: 0.5576 - val_accuracy: 0.7357\n",
            "Epoch 7/200\n",
            "644/644 [==============================] - 8s 12ms/step - loss: 0.5583 - accuracy: 0.7275 - val_loss: 0.5581 - val_accuracy: 0.7353\n",
            "Epoch 8/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5581 - accuracy: 0.7282 - val_loss: 0.5589 - val_accuracy: 0.7322\n",
            "Epoch 9/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5563 - accuracy: 0.7290 - val_loss: 0.5547 - val_accuracy: 0.7351\n",
            "Epoch 10/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5557 - accuracy: 0.7271 - val_loss: 0.5562 - val_accuracy: 0.7362\n",
            "Epoch 11/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5566 - accuracy: 0.7273 - val_loss: 0.5516 - val_accuracy: 0.7353\n",
            "Epoch 12/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5552 - accuracy: 0.7283 - val_loss: 0.5499 - val_accuracy: 0.7366\n",
            "Epoch 13/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5546 - accuracy: 0.7297 - val_loss: 0.5494 - val_accuracy: 0.7361\n",
            "Epoch 14/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5536 - accuracy: 0.7298 - val_loss: 0.5519 - val_accuracy: 0.7380\n",
            "Epoch 15/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5534 - accuracy: 0.7299 - val_loss: 0.5522 - val_accuracy: 0.7362\n",
            "Epoch 16/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5524 - accuracy: 0.7294 - val_loss: 0.5502 - val_accuracy: 0.7378\n",
            "Epoch 17/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5525 - accuracy: 0.7294 - val_loss: 0.5490 - val_accuracy: 0.7372\n",
            "Epoch 18/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5516 - accuracy: 0.7297 - val_loss: 0.5519 - val_accuracy: 0.7374\n",
            "Epoch 19/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5514 - accuracy: 0.7301 - val_loss: 0.5488 - val_accuracy: 0.7376\n",
            "Epoch 20/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5503 - accuracy: 0.7291 - val_loss: 0.5483 - val_accuracy: 0.7380\n",
            "Epoch 21/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5497 - accuracy: 0.7302 - val_loss: 0.5514 - val_accuracy: 0.7357\n",
            "Epoch 22/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5499 - accuracy: 0.7298 - val_loss: 0.5490 - val_accuracy: 0.7378\n",
            "Epoch 23/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5500 - accuracy: 0.7282 - val_loss: 0.5458 - val_accuracy: 0.7382\n",
            "Epoch 24/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5493 - accuracy: 0.7308 - val_loss: 0.5470 - val_accuracy: 0.7359\n",
            "Epoch 25/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5485 - accuracy: 0.7309 - val_loss: 0.5467 - val_accuracy: 0.7388\n",
            "Epoch 26/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5477 - accuracy: 0.7299 - val_loss: 0.5479 - val_accuracy: 0.7357\n",
            "Epoch 27/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5483 - accuracy: 0.7296 - val_loss: 0.5468 - val_accuracy: 0.7364\n",
            "Epoch 28/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5479 - accuracy: 0.7307 - val_loss: 0.5462 - val_accuracy: 0.7388\n",
            "Epoch 29/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5471 - accuracy: 0.7305 - val_loss: 0.5448 - val_accuracy: 0.7378\n",
            "Epoch 30/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5467 - accuracy: 0.7314 - val_loss: 0.5494 - val_accuracy: 0.7351\n",
            "Epoch 31/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5467 - accuracy: 0.7314 - val_loss: 0.5480 - val_accuracy: 0.7333\n",
            "Epoch 32/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5464 - accuracy: 0.7312 - val_loss: 0.5472 - val_accuracy: 0.7374\n",
            "Epoch 33/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5462 - accuracy: 0.7319 - val_loss: 0.5485 - val_accuracy: 0.7368\n",
            "Epoch 34/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5461 - accuracy: 0.7310 - val_loss: 0.5462 - val_accuracy: 0.7370\n",
            "Epoch 35/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5457 - accuracy: 0.7313 - val_loss: 0.5478 - val_accuracy: 0.7378\n",
            "Epoch 36/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5459 - accuracy: 0.7324 - val_loss: 0.5453 - val_accuracy: 0.7364\n",
            "Epoch 37/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5452 - accuracy: 0.7327 - val_loss: 0.5456 - val_accuracy: 0.7390\n",
            "Epoch 38/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5454 - accuracy: 0.7328 - val_loss: 0.5466 - val_accuracy: 0.7392\n",
            "Epoch 39/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5451 - accuracy: 0.7329 - val_loss: 0.5462 - val_accuracy: 0.7366\n",
            "Epoch 40/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5443 - accuracy: 0.7322 - val_loss: 0.5479 - val_accuracy: 0.7374\n",
            "Epoch 41/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5445 - accuracy: 0.7319 - val_loss: 0.5443 - val_accuracy: 0.7397\n",
            "Epoch 42/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5440 - accuracy: 0.7331 - val_loss: 0.5465 - val_accuracy: 0.7376\n",
            "Epoch 43/200\n",
            "644/644 [==============================] - 8s 12ms/step - loss: 0.5441 - accuracy: 0.7329 - val_loss: 0.5462 - val_accuracy: 0.7345\n",
            "Epoch 44/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5438 - accuracy: 0.7327 - val_loss: 0.5464 - val_accuracy: 0.7384\n",
            "Epoch 45/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5437 - accuracy: 0.7337 - val_loss: 0.5447 - val_accuracy: 0.7399\n",
            "Epoch 46/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5431 - accuracy: 0.7343 - val_loss: 0.5462 - val_accuracy: 0.7376\n",
            "Epoch 47/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5426 - accuracy: 0.7339 - val_loss: 0.5447 - val_accuracy: 0.7382\n",
            "Epoch 48/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5427 - accuracy: 0.7340 - val_loss: 0.5456 - val_accuracy: 0.7397\n",
            "Epoch 49/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5425 - accuracy: 0.7343 - val_loss: 0.5446 - val_accuracy: 0.7392\n",
            "Epoch 50/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5420 - accuracy: 0.7353 - val_loss: 0.5447 - val_accuracy: 0.7392\n",
            "Epoch 51/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5422 - accuracy: 0.7348 - val_loss: 0.5438 - val_accuracy: 0.7397\n",
            "Epoch 52/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.5446 - val_accuracy: 0.7347\n",
            "Epoch 53/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5411 - accuracy: 0.7336 - val_loss: 0.5486 - val_accuracy: 0.7394\n",
            "Epoch 54/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5411 - accuracy: 0.7348 - val_loss: 0.5445 - val_accuracy: 0.7397\n",
            "Epoch 55/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5408 - accuracy: 0.7344 - val_loss: 0.5434 - val_accuracy: 0.7380\n",
            "Epoch 56/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5408 - accuracy: 0.7348 - val_loss: 0.5460 - val_accuracy: 0.7390\n",
            "Epoch 57/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5404 - accuracy: 0.7354 - val_loss: 0.5449 - val_accuracy: 0.7380\n",
            "Epoch 58/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5402 - accuracy: 0.7356 - val_loss: 0.5469 - val_accuracy: 0.7376\n",
            "Epoch 59/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5402 - accuracy: 0.7347 - val_loss: 0.5473 - val_accuracy: 0.7382\n",
            "Epoch 60/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5395 - accuracy: 0.7354 - val_loss: 0.5461 - val_accuracy: 0.7380\n",
            "Epoch 61/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5391 - accuracy: 0.7355 - val_loss: 0.5510 - val_accuracy: 0.7366\n",
            "Epoch 62/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5394 - accuracy: 0.7350 - val_loss: 0.5481 - val_accuracy: 0.7378\n",
            "Epoch 63/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5390 - accuracy: 0.7355 - val_loss: 0.5515 - val_accuracy: 0.7357\n",
            "Epoch 64/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5401 - accuracy: 0.7358 - val_loss: 0.5455 - val_accuracy: 0.7380\n",
            "Epoch 65/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5386 - accuracy: 0.7356 - val_loss: 0.5462 - val_accuracy: 0.7351\n",
            "Epoch 66/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5381 - accuracy: 0.7357 - val_loss: 0.5485 - val_accuracy: 0.7368\n",
            "Epoch 67/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5382 - accuracy: 0.7364 - val_loss: 0.5502 - val_accuracy: 0.7362\n",
            "Epoch 68/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5382 - accuracy: 0.7359 - val_loss: 0.5479 - val_accuracy: 0.7384\n",
            "Epoch 69/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5380 - accuracy: 0.7358 - val_loss: 0.5484 - val_accuracy: 0.7380\n",
            "Epoch 70/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5380 - accuracy: 0.7366 - val_loss: 0.5528 - val_accuracy: 0.7372\n",
            "Epoch 71/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5381 - accuracy: 0.7364 - val_loss: 0.5479 - val_accuracy: 0.7374\n",
            "Epoch 72/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5376 - accuracy: 0.7363 - val_loss: 0.5523 - val_accuracy: 0.7349\n",
            "Epoch 73/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5377 - accuracy: 0.7359 - val_loss: 0.5528 - val_accuracy: 0.7366\n",
            "Epoch 74/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5371 - accuracy: 0.7364 - val_loss: 0.5489 - val_accuracy: 0.7361\n",
            "Epoch 75/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5366 - accuracy: 0.7364 - val_loss: 0.5527 - val_accuracy: 0.7364\n",
            "Epoch 76/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5365 - accuracy: 0.7370 - val_loss: 0.5545 - val_accuracy: 0.7353\n",
            "Epoch 77/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5365 - accuracy: 0.7369 - val_loss: 0.5533 - val_accuracy: 0.7343\n",
            "Epoch 78/200\n",
            "644/644 [==============================] - 8s 12ms/step - loss: 0.5368 - accuracy: 0.7370 - val_loss: 0.5547 - val_accuracy: 0.7357\n",
            "Epoch 79/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5362 - accuracy: 0.7377 - val_loss: 0.5559 - val_accuracy: 0.7374\n",
            "Epoch 80/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5363 - accuracy: 0.7363 - val_loss: 0.5553 - val_accuracy: 0.7374\n",
            "Epoch 81/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5361 - accuracy: 0.7367 - val_loss: 0.5536 - val_accuracy: 0.7386\n",
            "Epoch 82/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5357 - accuracy: 0.7367 - val_loss: 0.5580 - val_accuracy: 0.7267\n",
            "Epoch 83/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5365 - accuracy: 0.7355 - val_loss: 0.5595 - val_accuracy: 0.7376\n",
            "Epoch 84/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5360 - accuracy: 0.7362 - val_loss: 0.5547 - val_accuracy: 0.7374\n",
            "Epoch 85/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5355 - accuracy: 0.7371 - val_loss: 0.5641 - val_accuracy: 0.7370\n",
            "Epoch 86/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5360 - accuracy: 0.7364 - val_loss: 0.5560 - val_accuracy: 0.7382\n",
            "Epoch 87/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5363 - accuracy: 0.7358 - val_loss: 0.5549 - val_accuracy: 0.7362\n",
            "Epoch 88/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5374 - accuracy: 0.7373 - val_loss: 0.5493 - val_accuracy: 0.7368\n",
            "Epoch 89/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5357 - accuracy: 0.7374 - val_loss: 0.5584 - val_accuracy: 0.7355\n",
            "Epoch 90/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5351 - accuracy: 0.7375 - val_loss: 0.5575 - val_accuracy: 0.7362\n",
            "Epoch 91/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5349 - accuracy: 0.7372 - val_loss: 0.5570 - val_accuracy: 0.7359\n",
            "Epoch 92/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5352 - accuracy: 0.7379 - val_loss: 0.5588 - val_accuracy: 0.7370\n",
            "Epoch 93/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5347 - accuracy: 0.7378 - val_loss: 0.5559 - val_accuracy: 0.7359\n",
            "Epoch 94/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5345 - accuracy: 0.7368 - val_loss: 0.5626 - val_accuracy: 0.7349\n",
            "Epoch 95/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5345 - accuracy: 0.7369 - val_loss: 0.5656 - val_accuracy: 0.7372\n",
            "Epoch 96/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5346 - accuracy: 0.7370 - val_loss: 0.5646 - val_accuracy: 0.7376\n",
            "Epoch 97/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5342 - accuracy: 0.7374 - val_loss: 0.5541 - val_accuracy: 0.7361\n",
            "Epoch 98/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5344 - accuracy: 0.7390 - val_loss: 0.5638 - val_accuracy: 0.7341\n",
            "Epoch 99/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5345 - accuracy: 0.7376 - val_loss: 0.5580 - val_accuracy: 0.7368\n",
            "Epoch 100/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5342 - accuracy: 0.7381 - val_loss: 0.5635 - val_accuracy: 0.7372\n",
            "Epoch 101/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5338 - accuracy: 0.7388 - val_loss: 0.5592 - val_accuracy: 0.7366\n",
            "Epoch 102/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5343 - accuracy: 0.7380 - val_loss: 0.5654 - val_accuracy: 0.7370\n",
            "Epoch 103/200\n",
            "644/644 [==============================] - 6s 10ms/step - loss: 0.5349 - accuracy: 0.7380 - val_loss: 0.5592 - val_accuracy: 0.7382\n",
            "Epoch 104/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5347 - accuracy: 0.7376 - val_loss: 0.5562 - val_accuracy: 0.7382\n",
            "Epoch 105/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5333 - accuracy: 0.7387 - val_loss: 0.5674 - val_accuracy: 0.7380\n",
            "Epoch 106/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5335 - accuracy: 0.7389 - val_loss: 0.5610 - val_accuracy: 0.7372\n",
            "Epoch 107/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5332 - accuracy: 0.7390 - val_loss: 0.5681 - val_accuracy: 0.7347\n",
            "Epoch 108/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5346 - accuracy: 0.7386 - val_loss: 0.5737 - val_accuracy: 0.7353\n",
            "Epoch 109/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5339 - accuracy: 0.7383 - val_loss: 0.5690 - val_accuracy: 0.7359\n",
            "Epoch 110/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5333 - accuracy: 0.7387 - val_loss: 0.5607 - val_accuracy: 0.7347\n",
            "Epoch 111/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5343 - accuracy: 0.7386 - val_loss: 0.5615 - val_accuracy: 0.7364\n",
            "Epoch 112/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5325 - accuracy: 0.7386 - val_loss: 0.5565 - val_accuracy: 0.7370\n",
            "Epoch 113/200\n",
            "644/644 [==============================] - 8s 12ms/step - loss: 0.5330 - accuracy: 0.7387 - val_loss: 0.5650 - val_accuracy: 0.7380\n",
            "Epoch 114/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5330 - accuracy: 0.7392 - val_loss: 0.5663 - val_accuracy: 0.7329\n",
            "Epoch 115/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5323 - accuracy: 0.7384 - val_loss: 0.5692 - val_accuracy: 0.7361\n",
            "Epoch 116/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5332 - accuracy: 0.7387 - val_loss: 0.5722 - val_accuracy: 0.7376\n",
            "Epoch 117/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5327 - accuracy: 0.7393 - val_loss: 0.5735 - val_accuracy: 0.7355\n",
            "Epoch 118/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5335 - accuracy: 0.7392 - val_loss: 0.5618 - val_accuracy: 0.7368\n",
            "Epoch 119/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5328 - accuracy: 0.7389 - val_loss: 0.5671 - val_accuracy: 0.7341\n",
            "Epoch 120/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5334 - accuracy: 0.7396 - val_loss: 0.5587 - val_accuracy: 0.7362\n",
            "Epoch 121/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5330 - accuracy: 0.7387 - val_loss: 0.5619 - val_accuracy: 0.7361\n",
            "Epoch 122/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5320 - accuracy: 0.7392 - val_loss: 0.5678 - val_accuracy: 0.7380\n",
            "Epoch 123/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5327 - accuracy: 0.7395 - val_loss: 0.5649 - val_accuracy: 0.7380\n",
            "Epoch 124/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5321 - accuracy: 0.7394 - val_loss: 0.5664 - val_accuracy: 0.7380\n",
            "Epoch 125/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5321 - accuracy: 0.7391 - val_loss: 0.5674 - val_accuracy: 0.7364\n",
            "Epoch 126/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5323 - accuracy: 0.7378 - val_loss: 0.5598 - val_accuracy: 0.7364\n",
            "Epoch 127/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5319 - accuracy: 0.7392 - val_loss: 0.5682 - val_accuracy: 0.7390\n",
            "Epoch 128/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5321 - accuracy: 0.7384 - val_loss: 0.5696 - val_accuracy: 0.7364\n",
            "Epoch 129/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5320 - accuracy: 0.7399 - val_loss: 0.5647 - val_accuracy: 0.7392\n",
            "Epoch 130/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5319 - accuracy: 0.7388 - val_loss: 0.5723 - val_accuracy: 0.7370\n",
            "Epoch 131/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5329 - accuracy: 0.7395 - val_loss: 0.5594 - val_accuracy: 0.7351\n",
            "Epoch 132/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5328 - accuracy: 0.7382 - val_loss: 0.5595 - val_accuracy: 0.7362\n",
            "Epoch 133/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5316 - accuracy: 0.7392 - val_loss: 0.5663 - val_accuracy: 0.7349\n",
            "Epoch 134/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5320 - accuracy: 0.7391 - val_loss: 0.5676 - val_accuracy: 0.7339\n",
            "Epoch 135/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5315 - accuracy: 0.7392 - val_loss: 0.5773 - val_accuracy: 0.7372\n",
            "Epoch 136/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5315 - accuracy: 0.7396 - val_loss: 0.5701 - val_accuracy: 0.7368\n",
            "Epoch 137/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5313 - accuracy: 0.7397 - val_loss: 0.5761 - val_accuracy: 0.7337\n",
            "Epoch 138/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5313 - accuracy: 0.7391 - val_loss: 0.5762 - val_accuracy: 0.7355\n",
            "Epoch 139/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5321 - accuracy: 0.7392 - val_loss: 0.5678 - val_accuracy: 0.7374\n",
            "Epoch 140/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5316 - accuracy: 0.7388 - val_loss: 0.5727 - val_accuracy: 0.7370\n",
            "Epoch 141/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5309 - accuracy: 0.7397 - val_loss: 0.5700 - val_accuracy: 0.7345\n",
            "Epoch 142/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5311 - accuracy: 0.7392 - val_loss: 0.5748 - val_accuracy: 0.7355\n",
            "Epoch 143/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5308 - accuracy: 0.7394 - val_loss: 0.5783 - val_accuracy: 0.7361\n",
            "Epoch 144/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5307 - accuracy: 0.7400 - val_loss: 0.5780 - val_accuracy: 0.7372\n",
            "Epoch 145/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5312 - accuracy: 0.7400 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
            "Epoch 146/200\n",
            "644/644 [==============================] - 7s 12ms/step - loss: 0.5308 - accuracy: 0.7402 - val_loss: 0.5827 - val_accuracy: 0.7361\n",
            "Epoch 147/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5308 - accuracy: 0.7398 - val_loss: 0.5796 - val_accuracy: 0.7362\n",
            "Epoch 148/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5313 - accuracy: 0.7395 - val_loss: 0.5801 - val_accuracy: 0.7349\n",
            "Epoch 149/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5334 - accuracy: 0.7392 - val_loss: 0.5690 - val_accuracy: 0.7368\n",
            "Epoch 150/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5307 - accuracy: 0.7400 - val_loss: 0.5743 - val_accuracy: 0.7372\n",
            "Epoch 151/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5305 - accuracy: 0.7402 - val_loss: 0.5808 - val_accuracy: 0.7364\n",
            "Epoch 152/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5311 - accuracy: 0.7402 - val_loss: 0.5769 - val_accuracy: 0.7362\n",
            "Epoch 153/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5307 - accuracy: 0.7401 - val_loss: 0.5798 - val_accuracy: 0.7376\n",
            "Epoch 154/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5304 - accuracy: 0.7399 - val_loss: 0.5814 - val_accuracy: 0.7361\n",
            "Epoch 155/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5303 - accuracy: 0.7398 - val_loss: 0.5812 - val_accuracy: 0.7362\n",
            "Epoch 156/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5305 - accuracy: 0.7397 - val_loss: 0.5816 - val_accuracy: 0.7366\n",
            "Epoch 157/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5315 - accuracy: 0.7398 - val_loss: 0.5670 - val_accuracy: 0.7372\n",
            "Epoch 158/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5322 - accuracy: 0.7399 - val_loss: 0.5684 - val_accuracy: 0.7370\n",
            "Epoch 159/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5303 - accuracy: 0.7400 - val_loss: 0.5736 - val_accuracy: 0.7372\n",
            "Epoch 160/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5299 - accuracy: 0.7402 - val_loss: 0.5821 - val_accuracy: 0.7366\n",
            "Epoch 161/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5302 - accuracy: 0.7405 - val_loss: 0.5783 - val_accuracy: 0.7362\n",
            "Epoch 162/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5304 - accuracy: 0.7400 - val_loss: 0.5807 - val_accuracy: 0.7362\n",
            "Epoch 163/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5305 - accuracy: 0.7398 - val_loss: 0.5710 - val_accuracy: 0.7374\n",
            "Epoch 164/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5324 - accuracy: 0.7393 - val_loss: 0.5712 - val_accuracy: 0.7374\n",
            "Epoch 165/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5307 - accuracy: 0.7395 - val_loss: 0.5729 - val_accuracy: 0.7376\n",
            "Epoch 166/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5306 - accuracy: 0.7398 - val_loss: 0.5799 - val_accuracy: 0.7362\n",
            "Epoch 167/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5299 - accuracy: 0.7401 - val_loss: 0.5805 - val_accuracy: 0.7359\n",
            "Epoch 168/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5307 - accuracy: 0.7398 - val_loss: 0.5796 - val_accuracy: 0.7353\n",
            "Epoch 169/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5306 - accuracy: 0.7403 - val_loss: 0.5790 - val_accuracy: 0.7357\n",
            "Epoch 170/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5310 - accuracy: 0.7395 - val_loss: 0.5644 - val_accuracy: 0.7357\n",
            "Epoch 171/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5309 - accuracy: 0.7402 - val_loss: 0.5838 - val_accuracy: 0.7368\n",
            "Epoch 172/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5304 - accuracy: 0.7395 - val_loss: 0.5746 - val_accuracy: 0.7368\n",
            "Epoch 173/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5304 - accuracy: 0.7396 - val_loss: 0.5767 - val_accuracy: 0.7361\n",
            "Epoch 174/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5304 - accuracy: 0.7400 - val_loss: 0.5841 - val_accuracy: 0.7376\n",
            "Epoch 175/200\n",
            "644/644 [==============================] - 8s 13ms/step - loss: 0.5309 - accuracy: 0.7402 - val_loss: 0.5793 - val_accuracy: 0.7345\n",
            "Epoch 176/200\n",
            "644/644 [==============================] - 12s 19ms/step - loss: 0.5315 - accuracy: 0.7399 - val_loss: 0.5675 - val_accuracy: 0.7362\n",
            "Epoch 177/200\n",
            "644/644 [==============================] - 11s 17ms/step - loss: 0.5301 - accuracy: 0.7396 - val_loss: 0.5809 - val_accuracy: 0.7366\n",
            "Epoch 178/200\n",
            "644/644 [==============================] - 8s 12ms/step - loss: 0.5298 - accuracy: 0.7402 - val_loss: 0.5806 - val_accuracy: 0.7368\n",
            "Epoch 179/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5301 - accuracy: 0.7403 - val_loss: 0.5731 - val_accuracy: 0.7362\n",
            "Epoch 180/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5296 - accuracy: 0.7409 - val_loss: 0.5823 - val_accuracy: 0.7362\n",
            "Epoch 181/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5298 - accuracy: 0.7404 - val_loss: 0.5742 - val_accuracy: 0.7359\n",
            "Epoch 182/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5310 - accuracy: 0.7400 - val_loss: 0.5720 - val_accuracy: 0.7359\n",
            "Epoch 183/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5308 - accuracy: 0.7389 - val_loss: 0.5766 - val_accuracy: 0.7368\n",
            "Epoch 184/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5301 - accuracy: 0.7397 - val_loss: 0.5791 - val_accuracy: 0.7353\n",
            "Epoch 185/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5299 - accuracy: 0.7406 - val_loss: 0.5832 - val_accuracy: 0.7351\n",
            "Epoch 186/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5293 - accuracy: 0.7398 - val_loss: 0.5978 - val_accuracy: 0.7359\n",
            "Epoch 187/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5303 - accuracy: 0.7405 - val_loss: 0.5970 - val_accuracy: 0.7362\n",
            "Epoch 188/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5301 - accuracy: 0.7396 - val_loss: 0.5935 - val_accuracy: 0.7374\n",
            "Epoch 189/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5304 - accuracy: 0.7401 - val_loss: 0.5908 - val_accuracy: 0.7353\n",
            "Epoch 190/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5314 - accuracy: 0.7400 - val_loss: 0.5745 - val_accuracy: 0.7355\n",
            "Epoch 191/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5299 - accuracy: 0.7400 - val_loss: 0.5802 - val_accuracy: 0.7361\n",
            "Epoch 192/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5298 - accuracy: 0.7402 - val_loss: 0.5754 - val_accuracy: 0.7372\n",
            "Epoch 193/200\n",
            "644/644 [==============================] - 8s 12ms/step - loss: 0.5303 - accuracy: 0.7398 - val_loss: 0.5820 - val_accuracy: 0.7372\n",
            "Epoch 194/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5300 - accuracy: 0.7401 - val_loss: 0.5865 - val_accuracy: 0.7372\n",
            "Epoch 195/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5297 - accuracy: 0.7406 - val_loss: 0.5893 - val_accuracy: 0.7378\n",
            "Epoch 196/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5297 - accuracy: 0.7400 - val_loss: 0.5916 - val_accuracy: 0.7374\n",
            "Epoch 197/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5297 - accuracy: 0.7406 - val_loss: 0.5936 - val_accuracy: 0.7366\n",
            "Epoch 198/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5304 - accuracy: 0.7400 - val_loss: 0.5791 - val_accuracy: 0.7368\n",
            "Epoch 199/200\n",
            "644/644 [==============================] - 7s 10ms/step - loss: 0.5306 - accuracy: 0.7394 - val_loss: 0.5905 - val_accuracy: 0.7355\n",
            "Epoch 200/200\n",
            "644/644 [==============================] - 7s 11ms/step - loss: 0.5305 - accuracy: 0.7388 - val_loss: 0.5771 - val_accuracy: 0.7357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy of the model during training\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HWumzIA9eouy",
        "outputId": "211c2d2d-ffc0-4471-c394-5fcb052a6871"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GDYiER4YLGHw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJbFFcP45l2C",
        "outputId": "b95d2b88-95ce-47ee-8b6e-c188f0bfefef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 7.5952 - accuracy: 0.7278 - 1s/epoch - 4ms/step\n",
            "Loss: 7.595183372497559, Accuracy: 0.7278134226799011\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Vl98Q7pI5l2C"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "model.save(\"AlphabetSoupCharity_Optimization.h5\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}